{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ec7bb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "File : Notebook Vision\n",
    "Author : Benoît Gallois\n",
    "Date : 19 nov 2023\n",
    "Definition of the vision functions that can detect the position of the obstacles, robot and goal area.\n",
    "'''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "IMAGE_PATH = \"map3.jpeg\"\n",
    "\n",
    "# Definition of the colours thresholds\n",
    "LOWER_RED = np.array([0, 100, 100])\n",
    "UPPER_RED = np.array([10, 255, 255])\n",
    "\n",
    "LOWER_BLUE = np.array([100, 100, 100])\n",
    "UPPER_BLUE = np.array([140, 255, 255])\n",
    "\n",
    "LOWER_GREEN = np.array([40, 40, 40])\n",
    "UPPER_GREEN = np.array([80, 255, 255])\n",
    "\n",
    "LOWER_BLACK = np.array([0, 0, 0])\n",
    "UPPER_BLACK = np.array([179, 255, 30])\n",
    "\n",
    "# Definition of the size of contours considered as noise\n",
    "NOISY_CONTOUR_LENGHT = 2000\n",
    "'''\n",
    "\n",
    "\n",
    "def detect_area(image_path, lower_colour, upper_colour):\n",
    "    '''\n",
    "    @brief   Detects areas corresponding to a color and returns the coordinates of the vertices of these areas.\n",
    " \n",
    "    @param   image_path   -> \"folder_of_image/name_image.jpeg\"\n",
    "             lower_colour -> LOWER_RED, LOWER_BLACK, LOWER_BLUE, LOWER_GREEN\n",
    "             upper_colour -> UPPER_RED, UPPER_BLACK, UPPER_BLUE, UPPER_GREEN\n",
    "    \n",
    "    @return  coords       -> list of the coordinates of the vertices for each areas\n",
    "    '''\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    height, width, _ = image.shape      # Give the size of the image\n",
    "\n",
    "    # Converts the image in the HSV space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Filter the image to retain only pixels of the desired color\n",
    "    mask = cv2.inRange(hsv, lower_colour, upper_colour)\n",
    "\n",
    "    # Blur masks to reduce noise\n",
    "    blurred_mask = cv2.GaussianBlur(mask, (5, 5), 0)\n",
    "\n",
    "    # Find contours in the filtered mask\n",
    "    contours, _ = cv2.findContours(blurred_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # List to store coordinates of detected zones\n",
    "    coords = []\n",
    "\n",
    "    # Browse all contours found\n",
    "    for contour in contours:\n",
    "        \n",
    "        # Ignore small contours that could be noise\n",
    "        if cv2.contourArea(contour) > NOISY_CONTOUR_LENGHT:\n",
    "            \n",
    "            # Get the coordinates of the rectangle enclosing the area\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "            # Add the coordinates of the zone's vertices with a change of reference point (bottom left corner)\n",
    "            coords.append([(x, height - y), (x + w, height - y), (x + w, height - y - h), (x, height - y - h)])\n",
    "\n",
    "    return coords\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_robot_direction(front_area, back_area):\n",
    "    '''\n",
    "    @brief   Calculates the direction vector of the robot.\n",
    " \n",
    "    @param   front_area   -> List of coordinates for the front area (blue)\n",
    "             back_area    -> List of coordinates for the back area (green)\n",
    "    \n",
    "    @return  direction    -> tuple represents the direction vector coordinates\n",
    "                             list represents the midpoint coordinates\n",
    "    '''\n",
    "    \n",
    "    # Calculate the centroid of the front area (blue)\n",
    "    front_centroid = np.mean(np.array(front_area).reshape(-1, 2), axis=0)\n",
    "    \n",
    "    # Calculate the centroid of the back area (green)\n",
    "    back_centroid = np.mean(np.array(back_area).reshape(-1, 2), axis=0)\n",
    "    \n",
    "    # Calculate the direction vector of the robot\n",
    "    direction = (front_centroid - back_centroid).astype(int)\n",
    "    \n",
    "    # Calculate the midpoint between the centroids\n",
    "    midpoint = ((front_centroid + back_centroid) / 2).astype(int)\n",
    "    \n",
    "    return tuple(direction), midpoint\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_area_centroid(area_coordinates):\n",
    "    '''\n",
    "    @brief   Calculates the centroid coordinates of an area.\n",
    " \n",
    "    @param   area_coordinates -> List of coordinates area\n",
    "    \n",
    "    @return  centroid         -> List that represents the centroid coordinates\n",
    "    '''\n",
    "    \n",
    "    # Calculate the centroid of the area\n",
    "    centroid = np.mean(np.array(area_coordinates).reshape(-1, 2), axis=0)\n",
    "    \n",
    "    return centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c52f3f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the contours of each areas\n",
    "obstacles = detect_area(IMAGE_PATH, LOWER_BLACK, UPPER_BLACK)\n",
    "goal_area = detect_area(IMAGE_PATH, LOWER_RED, UPPER_RED)\n",
    "front_robot_area = detect_area(IMAGE_PATH, LOWER_BLUE, UPPER_BLUE)\n",
    "back_robot_area = detect_area(IMAGE_PATH, LOWER_GREEN, UPPER_GREEN)\n",
    "\n",
    "# Find the robot direction vector and its midpoint\n",
    "robot_direction = calculate_robot_direction(front_robot_area[0], back_robot_area[0])\n",
    "\n",
    "# Find the centroid of the goal area\n",
    "goal_centroid = calculate_area_centroid(goal_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "308a8aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordonnées obstacles noirs : [[(371, 1178), (1245, 1178), (1245, 906), (371, 906)], [(1605, 3481), (2100, 3481), (2100, 3203), (1605, 3203)]]\n",
      "Coordonnées zone d'arrivée : [[(350, 2803), (1332, 2803), (1332, 1822), (350, 1822)]]\n",
      "Coordonnées zone bleue : [[(1427, 2139), (2457, 2139), (2457, 1060), (1427, 1060)]]\n",
      "Coordonnées zone verte : [[(1670, 1912), (2900, 1912), (2900, 659), (1670, 659)]]\n",
      "Vecteur direction du robot : (-343, 314)\n",
      "Midpoint entre les centroids des zones verte et bleue : [2113 1442]\n",
      "Centroid de la goal area : [ 841.  2312.5]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Coordonnées obstacles noirs :\", obstacles)\n",
    "\n",
    "print(\"Coordonnées zone d'arrivée :\", goal_area)\n",
    "\n",
    "print(\"Coordonnées zone bleue :\", front_robot_area)\n",
    "\n",
    "print(\"Coordonnées zone verte :\", back_robot_area)\n",
    "\n",
    "print(\"Vecteur direction du robot :\", robot_direction[0])\n",
    "\n",
    "print(\"Midpoint entre les centroids des zones verte et bleue :\", robot_direction[1])\n",
    "\n",
    "print(\"Centroid de la goal area :\", goal_centroid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3f988e",
   "metadata": {},
   "source": [
    "## A Faire\n",
    "\n",
    "- augmenter largeur des obstacles virtuellement \n",
    "- donner centroide de la zone verte -> centre entre les deux roues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
